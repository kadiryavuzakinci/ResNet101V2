{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1CgkcdXOesLsBChjMcB6TTJ1Pi28DtSQD","authorship_tag":"ABX9TyM/OzSM2dylJEXu107xcQfr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"t2bbhmbMVZZl","executionInfo":{"status":"ok","timestamp":1702921528186,"user_tz":-180,"elapsed":6925,"user":{"displayName":"Kadir Yvz","userId":"12513518656632757413"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torchvision\n","from torchvision import transforms, datasets\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.metrics import confusion_matrix, f1_score\n","import numpy as np\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","source":["# Define your custom dataset\n","class CustomDataset(Dataset):\n","    def __init__(self, data, labels, transform=None):\n","        self.data = data\n","        self.labels = labels\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        image = self.data[idx]\n","        label = self.labels[idx]\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        return image, label\n"],"metadata":{"id":"HtXUKyFK_esR","executionInfo":{"status":"ok","timestamp":1702921529971,"user_tz":-180,"elapsed":344,"user":{"displayName":"Kadir Yvz","userId":"12513518656632757413"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["train_data = 'path/your/data'\n","train_labels = 'path/your/data'\n","test_data = 'path/your/data'\n","test_labels = 'path/your/data'\n","\n","data_transforms = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","# Create an instance of your custom dataset\n","train_dataset = CustomDataset(train_data, train_labels, transform=transforms)\n","\n","# Create a data loader for training\n","batch_size = 32\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","\n","# Create an instance of your custom dataset\n","test_dataset = CustomDataset(test_data, test_labels, transform=transforms)\n","\n","# Create a data loader for training\n","batch_size = 32\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n"],"metadata":{"id":"l0QW3m43_x1a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class BasicBlock(nn.Module):\n","  expansion=1\n","\n","  def __init__(self, in_planes, planes, stride=1):\n","    super(BasicBlock, self).__init__()\n","\n","    self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","    self.bn1 = nn.BatchNorm2d(planes)\n","    self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n","    self.bn2 = nn.BatchNorm2d(planes)\n","\n","    self.shortcut = nn.Sequential()\n","    if stride != 1 or in_planes != self.expansion * planes:\n","      self.shortcut = nn.Sequential(\n","          nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n","          nn.BatchNorm2d(self.expansion * planes)\n","      )\n","\n","\n","\n","  def forward(self,x):\n","    out = F.relu(self.bn1(self.conv1(x)))\n","    out = self.bn2(self.conv2(out))\n","    out += self.shortcut(x)\n","    out = F.relu(out)\n","    return out\n","\n","\n","class ResNet101V2(nn.Module):\n","  def __init__(self, block, num_blocks, num_classes=1000):\n","    super(ResNet101V2, self).__init__()\n","    self.in_planes = 64\n","\n","    self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n","    self.bn1 = nn.BatchNorm2d(64)\n","    self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","\n","    self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n","    self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n","    self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n","    self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n","\n","    self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n","    self.fc = nn.Linear(512 * block.expansion, num_classes)\n","\n","\n","  def _make_layer(self, block, planes, num_blocks, stride):\n","    strides = [stride] + [1] * (num_blocks - 1)\n","    layers = []\n","    for stride in strides:\n","      layers.append(block(self.in_planes, planes, stride))\n","      self.in_planes = planes * block.expansion\n","    return nn.Sequential(*layers)\n","\n","  def forward(self, x):\n","    x = F.relu(self.bn1(self.conv1(x)))\n","    s = self.maxpool(x)\n","\n","    x = self.layer1(x)\n","    x = self.layer2(x)\n","    x = self.layer3(x)\n","    x = self.layer4(x)\n","\n","    x = self.avgpool(x)\n","    x = torch.flatten(x, 1)\n","    x = self.fc(x)\n","\n","    return x\n","\n","#ResNet101V2 = ResNet101V2(BasicBlock, [3, 4, 23 ,3])"],"metadata":{"id":"DOZd37WBhMAB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train(model, train_loader, criterion, optimizer, device):\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    model.train()\n","    running_loss = 0.0\n","    for inputs, targets in train_loader:\n","        inputs, targets = inputs.to(device), targets.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, targets)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item() * inputs.size(0)\n","\n","    epoch_loss = running_loss / len(train_loader.dataset)\n","    return epoch_loss"],"metadata":{"id":"WzP0HXCwskBw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model = ResNet101V2(num_classes=...).to(device)  # 'device' should be torch.device('cuda') for GPU usage\n","    dataset = CustomDataset(...)\n","    train_loader = torch.utils.data.DataLoader(dataset, batch_size=..., shuffle=True)\n","\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","\n","    epochs = 10\n","    for epoch in range(epochs):\n","        train_loss = train(model, train_loader, criterion, optimizer, device)\n","        print(f\"Epoch [{epoch+1}/{epochs}] - Loss: {train_loss}\")"],"metadata":{"id":"680fq3l4tk-5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define your evaluation function\n","def evaluate(model, data_loader, device):\n","    model.eval()\n","    all_predictions = []\n","    all_targets = []\n","\n","    with torch.no_grad():\n","        for inputs, targets in data_loader:\n","            inputs, targets = inputs.to(device), targets.to(device)\n","            outputs = model(inputs)\n","            _, predicted = torch.max(outputs, 1)\n","\n","            all_predictions.extend(predicted.cpu().numpy())\n","            all_targets.extend(targets.cpu().numpy())\n","\n","    f1 = f1_score(all_targets, all_predictions, average='weighted')\n","    cm = confusion_matrix(all_targets, all_predictions)\n","\n","    return f1, cm\n","\n","# Assuming you have a separate validation dataset and data loader\n","# val_data = ...\n","# val_labels = ...\n","# val_dataset = CustomDataset(val_data, val_labels, transform=transform)\n","# val_loader = DataLoader(val_dataset, batch_size=batch_size)\n","\n","# Evaluate the model\n","if __name__ == \"__main__\":\n","\n","    epochs = 10\n","    for epoch in range(epochs):\n","        train_loss = train(model, train_loader, criterion, optimizer, device)\n","        print(f\"Epoch [{epoch+1}/{epochs}] - Loss: {train_loss}\")\n","\n","    # Evaluation on validation set\n","    f1_score_val, confusion_matrix_val = evaluate(model, test_loader, device)\n","    print(f\"Validation F1 Score: {f1_score_val}\")\n","    print(\"Confusion Matrix:\")\n","    print(confusion_matrix_val)\n"],"metadata":{"id":"ipXwWWrkBN5z"},"execution_count":null,"outputs":[]}]}